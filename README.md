# ğŸ“„ Document Retrieval QA (RAG with LangChain + LangGraph)

A lightweight **Retrieval-Augmented Generation (RAG)** app built with **Streamlit**, combining **LangChain** and **LangGraph**.
This project ingests documents (URLs, PDFs, and text files), stores them in a FAISS vector database, and lets you query them with LLM-powered answers grounded in your data.

---

## âœ¨ Features

* ğŸ”— **Document ingestion**: Load from web URLs, PDF directories, or `.txt` files.
* ğŸ“‘ **Chunking & preprocessing**: Recursive text splitting for better embedding + retrieval.
* ğŸ§  **Vector store**: Store & retrieve embeddings using **FAISS**.
* âš¡ **Retriever + LLM pipeline**: Powered by `langchain` + `langgraph`.
* ğŸ› **Streamlit app**: Interactive frontend for querying your documents.
* ğŸ’¾ **Persistence**: Save/load vector stores locally for reuse.

---

## ğŸ—ï¸ Project Structure

```bash
ProjectRAG/
â”œâ”€â”€ data/                   # Input sources (e.g. url.txt)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/             # App configuration
â”‚   â”œâ”€â”€ document_ingestion/ # Document loading + preprocessing
â”‚   â”œâ”€â”€ graph_builder/      # Graph-based pipelines (LangGraph)
â”‚   â”œâ”€â”€ nodes/              # RAG nodes (retrieval + answer generation)
â”‚   â”œâ”€â”€ state/              # Shared state for pipeline
â”‚   â””â”€â”€ vector_store/       # FAISS vector store utilities
â”œâ”€â”€ streamlit_app.py        # Main Streamlit app
â”œâ”€â”€ test_app.py             # Test scripts / prototyping
â”œâ”€â”€ vectorstore/            # Saved FAISS index
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1. Clone the repo

```bash
git clone https://github.com/bhupencoD3/doc-retrieval-qa.git
cd doc-retrieval-qa
```

### 2. Create & activate environment

```bash
conda create -n rag_app python=3.11 -y
conda activate rag_app
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Set up API key

Create a `.env` file in the project root:

```
OPENAI_API_KEY=your_api_key_here
```

### 5. Run the app

```bash
streamlit run streamlit_app.py
```

---

## ğŸ› ï¸ How It Works

1. **Document Ingestion**

   * `DocumentProcessor` loads sources (URLs, PDFs, `.txt`) and splits them into chunks.

2. **Vector Store**

   * `VectorStore` embeds docs with OpenAIâ€™s `text-embedding-3-small` and stores them in **FAISS**.

3. **Retriever Node**

   * Retrieves top-`k` relevant chunks for a given query.

4. **Answer Generation Node**

   * `SimpleRAGNodes` combines the retrieved context + question, and uses an LLM to generate an answer.

5. **Streamlit Frontend**

   * Users interactively upload/query documents and see results.

---

## ğŸ“Œ Example Usage

```python
from src.document_ingestion.document_processor import DocumentProcessor
from src.vector_store.vector_store import VectorStore
from src.nodes.nodes import SimpleRAGNodes
from src.state.rag_state import RAGState

# 1. Load & process docs
processor = DocumentProcessor()
docs = processor.process_sources(["data/url.txt"])

# 2. Create vector store
vs = VectorStore()
vs.create_vectorstore(docs)
retriever = vs.get_retriever()

# 3. Run retrieval + answer
rag_nodes = SimpleRAGNodes(retriever, llm)
state = RAGState(question="What is LangGraph?")
result = rag_nodes.generate_answer(state)
print(result["answer"])
```

---

## ğŸ“‹ Requirements

* Python 3.9+
* OpenAI API key

Main libraries:

* `langchain`, `langgraph`, `streamlit`
* `faiss-cpu`, `openai`, `pypdf`, `beautifulsoup4`

Full list in [requirements.txt](requirements.txt).

---

## ğŸ“š Roadmap

* [ ] Add **multi-node LangGraph pipeline** (e.g., React-style reasoning).
* [ ] Support **more file formats** (Word, Markdown).
* [ ] Enhance UI with chat-style interface in Streamlit.
* [ ] Integrate monitoring (Prometheus/Grafana).

---

## ğŸ“œ License

This project is licensed under the MIT License.

---

## ğŸ™Œ Acknowledgments

* [LangChain](https://github.com/langchain-ai/langchain)
* [LangGraph](https://github.com/langchain-ai/langgraph)
* [Streamlit](https://streamlit.io/)
